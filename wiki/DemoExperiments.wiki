#summary Getting started with DKPro TC: Demo Experiments

=Introduction=
_If you are using version 0.5.0, please change to the following [DemoExperiments_0_5_0 tutorial]._

In this quick start guide, we assume a certain familiarity with machine learning, natural language processing and the respective terminology. This document is not intended to be an introduction into these topics in general.

Please make sure that you have set up an environment variable `DKPRO_HOME`. The variable should point to a (possibly yet empty) directory which is intended to store any sort of resources which are to be used by any DKPro component. One way to set the variable `DKPRO_HOME` (there are several other ways) is to include the following line of code at the beginning of the main method of your experiment class:

{{{
System.setProperty("DKPRO_HOME", "pathToYourDKproDirectory");
// example of pathToYourDKproDirectory: /home/user/workspace/DKPRO_HOME 
}}}

DKPro TC comes with a collection of demo experiments which show various ways to define your experiment setups.

Currently, there are two example projects which represent TC experiments in Java and Groovy:
{{{
de.tudarmstadt.ukp.dkpro.tc.examples-gpl
de.tudarmstadt.ukp.dkpro.tc.examples-groovy-gpl
}}}

They are sorted into packages based on their feature and learning modes, e.g. 
{{{
TwentyNewsgroupsDemo
}}} 
can be found in the package
{{{
de.tudarmstadt.ukp.dkpro.tc.examples.single.document
}}}
as it demonstrates a single-label classification experiment with entire documents as classification objects. For an explanation of feature and learning modes, please see below. 

All example projects come with a set of data and can be run right away. The _twentynewsgroups_ experiment is a binary, single-label classification task. The _reuters_ example is a multi-label classification task.  The _regression_ demo shows how to use DKPro-TC for regression experiments. The _pairtwentynewsgroups_ demo is a text-pair classification task (`pair` feature mode).
If you don't know where to start, go with the twentynewsgroups demo first, as it has the most extensive documentation and configuration classes.

==Binary Classification with DKPro-TC: twentynewsgroups demo==

It might be advisable to open the code in parallel to reading this tutorial, as we will not copy the whole code in here.

There are two ways to run the experiment:
   * `TwentyNewsgroupsDemo.groovy` (Groovy configuration)
   * `TwentyNewsgroupsDemo.java` (Java configuration)

===TwentyNewsgroupsGroovyExperiment===

It takes care of 

  * loading the data
  * extracting features (which feature extractors are used and how to configure them)
  * training classifiers (which classifiers to use and how to configure them)
  * evaluating classifiers (either with designated train/test sets or using cross-validation)
  * writing results (which reports to use)

Parameters which should be tested for different values and combinations will be defined as [Discriminators here]. These parameters are usually prefixed with _dim_ and will be injected into the `ParameterSpace`.

The input data and reader(s) are defined as `DimensionBundle`.

{{{
def dimReaders = Dimension.createBundle("readers", [
   readerTrain: TwentyNewsgroupsCorpusReader.class,
   readerTrainParams: [
      TwentyNewsgroupsCorpusReader.PARAM_SOURCE_LOCATION,
      corpusFilePathTrain,
      TwentyNewsgroupsCorpusReader.PARAM_LANGUAGE,
      languageCode,
      TwentyNewsgroupsCorpusReader.PARAM_PATTERNS,
      TwentyNewsgroupsCorpusReader.INCLUDE_PREFIX + "*/*.txt"
   ],
   readerTest: TwentyNewsgroupsCorpusReader.class,
   readerTestParams: [
      TwentyNewsgroupsCorpusReader.PARAM_SOURCE_LOCATION,
      corpusFilePathTest,
      TwentyNewsgroupsCorpusReader.PARAM_LANGUAGE,
      languageCode,
      TwentyNewsgroupsCorpusReader.PARAM_PATTERNS,
      TwentyNewsgroupsCorpusReader.INCLUDE_PREFIX + "*/*.txt"
   ]
]);
}}}

In this case, the `TwentyNewsgroupsCorpusReader` will read all the .txt-files that can be found in (sub-)directories of `corpusFilePathTrain`/`corpusFilePathTest`.

The collected data is then processed via

{{{
private AnalysisEngineDescription getPreprocessing()
}}}

In the given examples two preprocessing methods are used:

{{{
BreakIteratorSegmenter
OpenNlpPosTagger
}}}

A segmenter and a Part-of-Speech Tagger. 

The feature extractors which will be used are defined as

{{{
def dimFeatureSets = Dimension.create("featureSet"...
}}}

Any configuration parameters which can be set for the feature extractors (e.g. uni-, bi- or trigrams for n-gram features) are defined as follows:

{{{
def dimPipelineParameters = Dimension.create("pipelineParameters" ...
}}}

The classifiers as defined here:

{{{
def dimClassificationArgs = Dimension.create("classificationArguments"...
}}}

Finally, you need to set a _feature mode_ and a _learning mode_:

{{{
def dimFeatureMode = Dimension.create("featureMode"...
}}}

{{{
def dimLearningMode = Dimension.create("learningMode"...
}}}

The feature mode defines the type of feature extraction you want to apply to your data:
   * document: features are extracted from the entire text of your document
   * unit: features are extracted from a part (`unit`) of the document
   * pair: features are extracted from a pair of documents
   * sequence: features are extracted from `units` within a sequence

The learning mode defines whether the experiment is a classification task (either single- or multilabel), or a regression task.

For more information on feature and leanring modes, refer to the following paper:

[https://www.ukp.tu-darmstadt.de/fileadmin/user_upload/Group_UKP/publikationen/2014/DKProTCPreprint.pdf DKPro TC: A Java-based Framework for Supervised Learning Experiments on Textual Data.]

There are two basic evaluation setups in DKPro-TC: x-fold-cross-validation and training/testing on specified sets.

====runCrossValidation()====

In the presented example, two folds are used:

{{{
def numFolds = 2;
}}}

Gluing all of the various parameters and processing tasks together to actually perform all the tasks is governed by `runCrossValidation()`

====runTrainTest()====

Similarly, for the designated test and train sets.

===Output===

In your `DKPRO_HOME` folder, you will find a set of directories storing intermediate and final evaluation results of your experiments: 
The `Evaluation...` folders (usually one for the TrainTest setup and one for Crossvalidation, named according to the experiment name setup of the overall BatchTask) contain the final results for all runs of the pipeline.
E.g., the `eval.xls` file contains information about the performance of the individual configurations (especially useful if you want to compare several classifiers or feature sets on the same data set). 
After an experiment has run, the path to the folder storing detailed results will be displayed on the console.

Once you got this example running as it is, you can start adapting various parameters:

  * using different data sets - which are completely up to you (also see [Readers here])
  * using different features - any that you can think of. Please have a look at the respective classes to get an idea about the parameters you might have to configure for each of the feature extractors.
  * using different classifiers - please refer to the Weka/Meka-JavaDoc for further information on that.