#summary Getting started with DKPro TC: Demo Experiments

=Introduction=

In this introduction, we assume a certain familiarity with machine learning, natural language processing and the respective terminology. This document is not intended to be an introduction into these topics in general.


Please make sure that you have set up an environment variable *DKPRO_HOME*. The variable should point to a (possibly yet empty) directory which is intended to store any sort of resources which are to be used by any DKPro component.

DKPro TC comes with a collection of demo experiments which show various ways to define your experiment setups.

Currently, there are four basic example experiments:

{{{
de.tudarmstadt.ukp.dkpro.tc.demo.reuters-gpl
de.tudarmstadt.ukp.dkpro.tc.demo.sentimentpolarity-gpl
de.tudarmstadt.ukp.dkpro.tc.demo.twentynewsgroups-gpl
de.tudarmstadt.ukp.dkpro.tc.demo.regression-gpl
}}}

All come with a set of data and can be run right away. The _reuters_ example is a multi-classification task, whereas the _twentynewsgroups_ and the _sentimentpolarity_ experiment are binary classification tasks. 
The _regression_ demo shows how to use DKPro-TC for regression experiments.

==Binary Classification with DKPro-TC: twentynewsgroups demo ==

It might be advisable to open the code in parallel to reading this tutorial, as we will not copy the whole code in here.

These are some of the files you should find in this project:

{{{
├── pom.xml
└── src
   ├── main.groovy...dkpro
   │                   └── twentynewsgroups
   │                          ├── io
   │                          │   └── TwentyNewsgroupsCorpusReader.java
   │                          ├── ParameterSpaceParser.java
   │                          ├── TwentyNewsgroupsExperiment.java
   │                          ├── TwentyNewsgroupsGroovyExperiment.groovy
   │                          └── TwentyNewsgroupsGroovyExtendedExperiment.groovy
   └─ main.resources
          ├── config
          │   └── train.json
          ├── data
          │   ├── bydate-test
          │   │   ├── alt.atheism
          │   │   ├── comp.graphics
          │   │   ├── comp.os.ms-windows.misc
          │   │   └── comp.sys.ibm.pc.hardware
          │   └── bydate-train
          │       ├── alt.atheism
          │       ├── comp.graphics
          │       ├── comp.os.ms-windows.misc
          │       └── comp.sys.ibm.pc.hardware
          ├── lab
          │   └── debug_context.xml
          └── log4j.properties
}}}

There are three ways to run the experiment:

`TwentyNewsgroupsExperiment` (Java configuration using a _JSON_ file and `ParameterSpaceParser` for configuration)
`TwentyNewsgroupsGroovyExperiment` (Groovy configuration re-using pre-configured Train/Test and CV setup)
`TwentyNewsgroupsGroovyExtendedExperiment` (Pure Groovy configuration)

===TwentyNewsgroupsGroovyExperiment===

It takes care of 

  * loading the data
  * extracting features (which feature extractors are used and how to configure them)
  * training classifiers (which classifiers to use and how to configure them)
  * evaluating classifiers (either with designated train/test sets or using cross-validation)
  * writing results (which reports to use)

Let's look at each of these individually:

{{{
    def corpusFilePathTrain = "src/main/resources/data/bydate-train";
    def corpusFilePathTest  ="src/main/resources/data/bydate-test";
    def languageCode = "en";
}}}

This defines the data to be used - split into training and testing data. The language is English.

The method 

{{{
private CollectionReaderDescription getReaderDesc(String corpusFilePath, String language)
}}}

takes the said paths and gathers the data to be processed. In this case all the .txt-files that can be found in (sub-)directories.

The collected data is then processed via

{{{
private AnalysisEngineDescription getPreprocessing()
}}}

In the given examples two preprocessing methods are used:

{{{
BreakIteratorSegmenter
OpenNlpPosTagger
}}}

A segmenter and a Part-of-Speech Tagger. 

From the words and the POS tags n-gram features are extracted - precisely uni-, bi- and trigram, as defined here:

{{{
def dimPipelineParameters = Dimension.create("pipelineParameters" ...
}}}

The feature extractors which will be used are defined as

{{{
def dimFeatureSets = Dimension.create("featureSet"...
}}}

along with their configuration

{{{
def dimFeatureParameters = Dimension.create("featureParameters",
}}}

The classifiers as defined here:

{{{
def dimClassificationArgs = Dimension.create("classificationArguments"...
}}}


Two basic train and test methods are implemented in this example: x-fold-cross-validation and training/testing on specified sets.

===runCrossValidation()===

In the presented example, two folds are used:

{{{
def dimFolds = Dimension.create("folds" , 2);
}}}

gluing all of the various parameters and processing tasks together to actually perform all the tasks is governed by

runCrossValidation()

===runTrainTest()===

And similarly for the designated test and train sets.

===main()===

This calls both the cross-validation and the train/test runs. Please note, that here it can be specified where the resulting data will be stored:

{{{
System.setProperty("DKPRO_HOME", "/the/path/to/my/results/");
}}}

There you will find a set of directories storing intermediate and final evaluation results of your experiments.

  * `Evaluation..CV..` contains the cross-validation results, whereas
  * `Evaluation..TrainTest..` contains the results on the test set.

E.g., the `eval.xls` file contains information of the performance of the individual classifiers (especially useful if you want to compare several classifiers on the same data set).

Once you got this example running as it is, you can start adapting various parameters:

  * using different data sets - which are completely up to you
  * using different features - any that you can think of. Please have a look at the respective classes to get an idea about the parameters you might have to configure for each of the feature extractors.
  * using different classifiers - please refer to the WEKA-JavaDoc for further information on that. Currently, we only support WEKA for classification.

==Multi-labelClassification with DKPro-TC: reuters demo ==

tbd.